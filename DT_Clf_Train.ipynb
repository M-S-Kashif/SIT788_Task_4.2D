{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4ba53c4",
   "metadata": {},
   "source": [
    "### Section 2: ML Practical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77cf4f1",
   "metadata": {},
   "source": [
    "#### Part 1: Loading all the Python libraries for the ML Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30f4443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing library for loading the data into Python\n",
    "import pandas as pd\n",
    "\n",
    "#Importing library for Pre-processing of the data\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Importing library for getting all the models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Importing library for splitting the data for learning and testing phases\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Importing library for getting all the metrics for performance evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "#Importing library for saving the models with the results\n",
    "#import pickle\n",
    "#import zipfile\n",
    "import os\n",
    "import joblib\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc608e4",
   "metadata": {},
   "source": [
    "#### Part 2: Data Ingestion and Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d5c1e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1      int64\n",
      "f2     object\n",
      "f3      int64\n",
      "f4     object\n",
      "f5      int64\n",
      "f6     object\n",
      "f7     object\n",
      "f8     object\n",
      "f9     object\n",
      "f10    object\n",
      "f11     int64\n",
      "f12     int64\n",
      "f13     int64\n",
      "f14    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Loading the dataset and print the data types of the columns...\n",
    "data = pd.read_csv(\"data1.csv\")\n",
    "df = data.infer_objects()\n",
    "print(df.dtypes[0:14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a29bfe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>f13</th>\n",
       "      <th>f14</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1                f2      f3         f4  f5                  f6  \\\n",
       "0  39         State-gov   77516  Bachelors  13       Never-married   \n",
       "1  50  Self-emp-not-inc   83311  Bachelors  13  Married-civ-spouse   \n",
       "2  38           Private  215646    HS-grad   9            Divorced   \n",
       "3  53           Private  234721       11th   7  Married-civ-spouse   \n",
       "4  28           Private  338409  Bachelors  13  Married-civ-spouse   \n",
       "\n",
       "                  f7             f8     f9     f10   f11  f12  f13  \\\n",
       "0       Adm-clerical  Not-in-family  White    Male  2174    0   40   \n",
       "1    Exec-managerial        Husband  White    Male     0    0   13   \n",
       "2  Handlers-cleaners  Not-in-family  White    Male     0    0   40   \n",
       "3  Handlers-cleaners        Husband  Black    Male     0    0   40   \n",
       "4     Prof-specialty           Wife  Black  Female     0    0   40   \n",
       "\n",
       "             f14  class  \n",
       "0  United-States      1  \n",
       "1  United-States      1  \n",
       "2  United-States      1  \n",
       "3  United-States      1  \n",
       "4           Cuba      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing the empty instances (or instances with white columns) of the dataset (lines in the file)\n",
    "for i in range (0,14):\n",
    "    if df.dtypes[i] != 'int64':\n",
    "        data.iloc[:,i] = df.iloc[:,i].map(lambda x:x.strip())\n",
    "array = data\n",
    "array.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a6180eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating the input columns and the target (output) columns...\n",
    "inputs = array.drop('class', axis='columns')\n",
    "target = array['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "307ce9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22 7 2671 ... 0 39 39]\n",
      " [33 6 2926 ... 0 12 39]\n",
      " [21 4 14086 ... 0 39 39]\n",
      " ...\n",
      " [41 4 7883 ... 0 39 39]\n",
      " [5 4 12881 ... 0 19 39]\n",
      " [35 5 17825 ... 0 39 39]]\n"
     ]
    }
   ],
   "source": [
    "#Converting categorical variables into non-categorical counterparts...\n",
    "\n",
    "labelenc = preprocessing.LabelEncoder()\n",
    "\n",
    "X= inputs.values\n",
    "Y= target.values\n",
    "\n",
    "for i in range (0,14):\n",
    "    X[:,i] = labelenc.fit_transform(X[:,i])\n",
    "    \n",
    "#This is how X (input array) and Y (output array) now looks like...\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06f25fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65707092",
   "metadata": {},
   "source": [
    "#### Part 3: Splitting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f03ef401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into a Validation Set...\n",
    "test_ratio = 0.2\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = test_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e71c96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26048, 14)\n",
      "(26048,)\n"
     ]
    }
   ],
   "source": [
    "#Visualizing the shape of the Training Dataset...\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4de2d089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6513, 14)\n",
      "(6513,)\n"
     ]
    }
   ],
   "source": [
    "#Visualizing the shape of the Testing Dataset...\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f0541b",
   "metadata": {},
   "source": [
    "#### Part 4: Training and Evaluating the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd125526",
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = DecisionTreeClassifier(criterion='entropy',max_features=13,max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c598b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting and Testing the Decision Tree Model (M1)...\n",
    "M1 = M1.fit(X_train,Y_train)\n",
    "M1_pred = M1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5be3176d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Model 1: Decision Tree--------------------------\n",
      "Accuracy Score:  85.10670965760787 %\n",
      "Confusion Matrix: \n",
      " [[ 936  620]\n",
      " [ 350 4607]]\n",
      "Hamming Loss:  14.893290342392138 %\n",
      "F1 Score:  0.9047525530243519\n",
      "Average Precision Curve:  0.8728916376063398\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------Model 1: Decision Tree--------------------------\")\n",
    "print(\"Accuracy Score: \", accuracy_score(Y_test,M1_pred)*100,\"%\")\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(Y_test,M1_pred))\n",
    "print(\"Hamming Loss: \", hamming_loss(Y_test,M1_pred)*100,\"%\")\n",
    "print(\"F1 Score: \", f1_score(Y_test,M1_pred))\n",
    "print(\"Average Precision Curve: \", average_precision_score(Y_test,M1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82cc26da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export the model to DTmodel.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['DTmodel.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the first Model into a Pickle File...\n",
    "# print(\"Export the model to DTmodel.pkl\")\n",
    "# f1= open('M1.pkl','wb')\n",
    "# pickle.dump(M1,f1)\n",
    "# f1.close\n",
    "print(\"Export the model to DTmodel.pkl\")\n",
    "joblib.dump(M1, \"DTmodel.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aee27413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Saving the first Model into a Zip File...\n",
    "# zipfile.ZipFile('model1.zip',mode='w').write('M1.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
